{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 모델 정의\n",
    "\n",
    "MNIST를 입력으로 하는 (BATCH, 28*28)\n",
    "\n",
    "2D Conv Encoder & Decoder로 이루어진 ConvVAE, ConvAE와\n",
    "\n",
    "Linear Encoder & Decoder로 이루어진 FlattenVAE, FlattenAE 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/model.py\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # 2D-Conv Encoder (shape : [Batches, channels, image(h), image(w)])\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                padding_mode='zeros'\n",
    "                ), # shape : (B, 1, 28, 28) -> (B, 16, 14, 14)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=64,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                padding_mode='zeros'\n",
    "                ), # shape : (B, 16, 14, 14) -> (B, 64, 7, 7)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # avg of Latent vecs (shape : [Batches, latent_dim])\n",
    "        self.fc_mu = nn.Linear(\n",
    "                        in_features=64*7*7, \n",
    "                        out_features=latent_dim\n",
    "                        )\n",
    "\n",
    "        # ln(variance) of Latent vecs (shape: [Batches, latent_dim])\n",
    "        self.fc_logvar = nn.Linear(\n",
    "                            in_features=64*7*7, \n",
    "                            out_features=latent_dim\n",
    "                            )\n",
    "\n",
    "        # 2D-Conv Decoder (shape : [Batches, ...SAME SHAPE WITH ORIGINAL DATA...])\n",
    "        self.fc_decoder = nn.Linear(\n",
    "                                in_features=latent_dim, \n",
    "                                out_features=64*7*7\n",
    "                                )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=64, \n",
    "                out_channels=16, \n",
    "                kernel_size=4, \n",
    "                stride=2, \n",
    "                padding=1,\n",
    "                padding_mode='zeros'\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=16, \n",
    "                out_channels=1, \n",
    "                kernel_size=4, \n",
    "                stride=2, \n",
    "                padding=1,\n",
    "                padding_mode='zeros'\n",
    "            ),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Params Init(Xavier uniform initialization)\n",
    "        self._init_weights()\n",
    "\n",
    "    \n",
    "    def encode(self, x):\n",
    "        encoded_x = self.encoder(x)\n",
    "        encoded_x_flatten = encoded_x.reshape(encoded_x.size(0), -1) # shape : (Batches, flatten_len of sample)\n",
    "        return self.fc_mu(encoded_x_flatten), self.fc_logvar(encoded_x_flatten)\n",
    "\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std_dev = torch.exp(0.5 * logvar) # standard deviation of Latent vecs\n",
    "        eps = torch.randn_like(std_dev)\n",
    "        \n",
    "        return mu + eps * std_dev\n",
    "    \n",
    "\n",
    "    def decode(self, latent_z):\n",
    "        preprocessed_z_in_2d = self.fc_decoder(latent_z).view(-1, 64, 7, 7) # shape : (Batches, 64, 7, 7)\n",
    "       \n",
    "        return self.decoder(preprocessed_z_in_2d)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        latent_z = self.reparameterize(mu, logvar)\n",
    "        reconst_x = self.decode(latent_z)\n",
    "\n",
    "        return reconst_x, mu, logvar, latent_z\n",
    "    \n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Linear, nn.Conv2d, nn.ConvTranspose2d)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "\n",
    "class FlattenVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # Linear Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # avg of Latent vecs\n",
    "        self.fc_mu = nn.Linear(128, latent_dim)\n",
    "\n",
    "        # ln(variance) of Latent vecs\n",
    "        self.fc_logvar = nn.Linear(128, latent_dim)\n",
    "\n",
    "        # Linear Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 28*28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Params Init(Xavier uniform initialization)\n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        encoded_x = self.encoder(x)\n",
    "\n",
    "        return self.fc_mu(encoded_x), self.fc_logvar(encoded_x)\n",
    "\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std_dev = torch.exp(0.5 * logvar) # standard deviation of Latent vecs\n",
    "        eps = torch.randn_like(std_dev)\n",
    "        \n",
    "        return mu + eps * std_dev\n",
    "    \n",
    "\n",
    "    def decode(self, latent_z):\n",
    "        decoded_x = self.decoder(latent_z)\n",
    " \n",
    "        return decoded_x.view(-1, 1, 28, 28)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        latent_z = self.reparameterize(mu, logvar)\n",
    "        reconst_x = self.decode(latent_z)\n",
    "\n",
    "        return reconst_x, mu, logvar, latent_z\n",
    "    \n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Linear,)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "\n",
    "class ConvAE(nn.Module):\n",
    "    def __init__(self, latent_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # 2D-Conv Encoder (shape : [Batches, channels, image(h), image(w)])\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                padding_mode='zeros'\n",
    "                ), # shape : (B, 1, 28, 28) -> (B, 16, 14, 14)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=64,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                padding_mode='zeros'\n",
    "                ), # shape : (B, 16, 14, 14) -> (B, 64, 7, 7)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Latent vecs (shape : [Batches, latent_dim])\n",
    "        self.fc_z = nn.Linear(\n",
    "                        in_features=64*7*7, \n",
    "                        out_features=latent_dim\n",
    "                        )\n",
    "\n",
    "        # 2D-Conv Decoder (shape : [Batches, ...SAME SHAPE WITH ORIGINAL DATA...])\n",
    "        self.fc_decoder = nn.Linear(\n",
    "                                in_features=latent_dim, \n",
    "                                out_features=64*7*7\n",
    "                                )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=64, \n",
    "                out_channels=16, \n",
    "                kernel_size=4, \n",
    "                stride=2, \n",
    "                padding=1,\n",
    "                padding_mode='zeros'\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=16, \n",
    "                out_channels=1, \n",
    "                kernel_size=4, \n",
    "                stride=2, \n",
    "                padding=1,\n",
    "                padding_mode='zeros'\n",
    "            ),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Params Init(Xavier uniform initialization)\n",
    "        self._init_weights()   \n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        encoded_x = self.encoder(x)\n",
    "        encoded_x_flatten = encoded_x.reshape(encoded_x.size(0), -1) # shape : (Batches, flatten_len of sample)\n",
    "\n",
    "        return self.fc_z(encoded_x_flatten)\n",
    "    \n",
    "\n",
    "    def decode(self, latent_z):\n",
    "        preprocessed_z_in_2d = self.fc_decoder(latent_z).view(-1, 64, 7, 7) # shape : (Batches, 64, 7, 7)\n",
    "        \n",
    "        return self.decoder(preprocessed_z_in_2d)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent_z = self.encode(x)\n",
    "        reconst_x = self.decode(latent_z)\n",
    "\n",
    "        return reconst_x, None, None, latent_z\n",
    "    \n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Linear, nn.Conv2d, nn.ConvTranspose2d)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "\n",
    "class FlattenAE(nn.Module):\n",
    "    def __init__(self, latent_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # Linear Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "\n",
    "        # Linear Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 28*28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Params Init(Xavier uniform initialization)\n",
    "        self._init_weights()\n",
    "\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "\n",
    "    def decode(self, latent_z):\n",
    "        decoded_x = self.decoder(latent_z)\n",
    "        return decoded_x.view(-1, 1, 28, 28) \n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        latent_z = self.encode(x)\n",
    "        reconst_x = self.decode(latent_z) \n",
    "\n",
    "        return reconst_x, None, None, latent_z\n",
    "    \n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Linear,)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loss function 정의\n",
    "\n",
    "입력 데이터 x와 복원 데이터 reconst_x 사이의 차이를 계산하여 모델이 데이터를 얼마나 잘 복원했는지(BCE 재구성 손실 계산, 데이터 충실도)\n",
    "\n",
    "잠재 공간 분포를 정규 분포와 얼마나 가깝게 유지했는지(KL Divergence 손실 계산, 규제)\n",
    "\n",
    "를 ${\\beta}$를 조절(${\\beta}$스케줄링)하며 KL항의 영향력을 학습 진행에 따라 조정할 수 있는 Loss Function 정의\n",
    "\n",
    "\n",
    "한줄요약 : 모델로 하여금 \"원본이미지를 충실히 복원하렴\" + \"잠재 변수 분포 정규화 시 균형도 충실히 맞추렴\"을 주문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/loss.py\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math\n",
    "\n",
    "def reconst_loss(reconst_x, x):\n",
    "    loss = F.binary_cross_entropy(reconst_x, x, reduction='sum')\n",
    "\n",
    "    return loss / x.size(0) # sum of BCE loss / batch_size\n",
    "\n",
    "\n",
    "def kl_divergence(mu, logvar):\n",
    "    kl = -0.5 * torch.sum( 1+logvar-mu.pow(2)-logvar.exp() )\n",
    "\n",
    "    return kl / mu.size(0) # sum of KLD / batch_size\n",
    "\n",
    "\n",
    "def beta(config, epoch):\n",
    "    if config['beta_schedule']['type'] == 'linear':\n",
    "        t = min(1.0, epoch/max(1, config['beta_schedule']['warmup_epochs']))\n",
    "        \n",
    "        return 1.0 + t*(config['beta_schedule']['max_beta']-1.0)\n",
    "    \n",
    "    elif config['beta_schedule']['type'] == 'cosine':\n",
    "        T = max(1.0, config['beta_schedule']['warmup_epochs'])\n",
    "        t = min(1.0, epoch / T)\n",
    "        \n",
    "        return 1.0 + 0.5*(1-math.cos(math.pi * t))*(config['beta_schedule']['max_beta'] - 1.0)\n",
    "    \n",
    "    return config['model']['beta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고] BCE + ${\\beta\\cdot}$ KLD는 이후 vae_train의 학습과정 중 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MNIST 데이터셋 준비하기\n",
    "\n",
    "MNIST 데이터셋을 각각 Train, Test용 DataLoader로 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/dataset.py\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "def get_loaders(root, name=\"MNIST\", batch_size=128, num_workers=0):\n",
    "    tfm = transforms.ToTensor()\n",
    "    dataset = datasets.MNIST if name==\"MNIST\" else datasets.FashionMNIST\n",
    "    train = dataset(root, train=True, download=True, transform=tfm)\n",
    "    test  = dataset(root, train=False, download=True, transform=tfm)\n",
    "    \n",
    "    train_loader= DataLoader(\n",
    "        dataset=train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 학습\n",
    "\n",
    "제곧내"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/vae_train.py\n",
    "\n",
    "from loss import *\n",
    "from visualization import *\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def vae_train(model, train_loader, test_loader, config, device=\"cuda\"):\n",
    "    model.train()\n",
    "\n",
    "    device = torch.device(config['device'])\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['train']['lr'])\n",
    "\n",
    "    out_dir = config['paths']['out_dir']\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in tqdm(range(1, config['train']['epochs']+1), total=len(train_loader), desc=f\"[EPOCH {epoch}] training...\"):\n",
    "        total = 0\n",
    "        reconst_total = 0\n",
    "        for x, _ in train_loader:\n",
    "            x = x.to(device)\n",
    "            # forward\n",
    "            reconst_x, mu, logvar, latent_z = model(x)\n",
    "\n",
    "            # loss\n",
    "            reconst_loss_term = reconst_loss(reconst_x, x)\n",
    "            beta_term = beta(config, epoch)\n",
    "            kl_divergence_term = kl_divergence(mu, logvar)\n",
    "            loss = reconst_loss_term + beta_term*kl_divergence_term\n",
    "            \n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total += loss.item()\n",
    "            reconst_total += reconst_loss_term.item()\n",
    "        \n",
    "        print(f\"[{epoch}] loss={total/len(train_loader):.4f} (beta={beta_term:.2f})\")\n",
    "        print(f\"[{epoch}] reconst_loss={reconst_total/len(train_loader):.4f} (beta={beta_term:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
